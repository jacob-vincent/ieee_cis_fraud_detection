{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/fraud/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import lightgbm\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(data_df, sparse=False):\n",
    "    \"\"\"Reduce memory usage of Pandas DF.\n",
    "    From https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "    \n",
    "    :param df: Pandas DF\n",
    "    :type df: :class:`pandas.DataFrame`\n",
    "    :return: Pandas DF\n",
    "    :rtype: :class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    megabyte = 1024**2\n",
    "    start_mem = data_df.memory_usage().sum()/megabyte\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "\n",
    "    for col in data_df.columns:\n",
    "        col_type = data_df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = data_df[col].min()\n",
    "            c_max = data_df[col].max()\n",
    "\n",
    "            if str(col_type).startswith('int') or str(col_type).startswith('uint'):\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    data_df[col] = data_df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    data_df[col] = data_df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    data_df[col] = data_df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    data_df[col] = data_df[col].astype(np.int64)\n",
    "            elif str(col_type).startswith('float'):\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    data_df[col] = data_df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    data_df[col] = data_df[col].astype(np.float32)\n",
    "                else:\n",
    "                    data_df[col] = data_df[col].astype(np.float64)\n",
    "        else:\n",
    "            data_df[col] = data_df[col].astype('category')\n",
    "\n",
    "    if sparse:\n",
    "        data_df = csr_matrix(data_df)\n",
    "        end_mem = (data_df.data.nbytes + data_df.indptr.nbytes + data_df.indices.nbytes)/megabyte\n",
    "    else:\n",
    "        end_mem = data_df.memory_usage().sum()/megabyte\n",
    "        \n",
    "    percent_change = 100*(start_mem-end_mem)/start_mem\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    print(f'Decreased by {percent_change:.1f}%')\n",
    "\n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_categoricals(data_df, keep_na=True):\n",
    "    \"\"\"\n",
    "    Take a dataframe, find the categorical data stored as strings, and explode those columns into dummy variables\n",
    "    \n",
    "    :param data_df: Input dataframe to examine for categorical data\n",
    "    :type data_df: :class:`pandas.DataFrame`\n",
    "    :return: Input dataframe with categorical data represented as dummy variables\n",
    "    :rype: :class:`pandas.DataFrame`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify categorical columns not already binarized\n",
    "    string_columns = []\n",
    "    for column in data_df.columns:\n",
    "        if data_df[column].dtype==\"O\":\n",
    "            string_columns.append(column)\n",
    "\n",
    "    # Create dummy variables for categorical columns\n",
    "    for c in string_columns:\n",
    "        dummy_df = pd.get_dummies(data_df[c], prefix=c, dummy_na=keep_na)\n",
    "        data_df = pd.concat([data_df, dummy_df], axis=1).drop(c, axis=1)\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_region(text_entry):\n",
    "    if str(text_entry)==\"nan\":\n",
    "        return \"nan\"\n",
    "    else:\n",
    "        return str(text_entry).split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_site(text_entry):\n",
    "    if str(text_entry)==\"nan\":\n",
    "        return \"nan\"\n",
    "    else:\n",
    "        return str(text_entry).split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = sys.argv[1]\n",
    "output_path = sys.argv[2]\n",
    "train_id = pd.read_csv(input_path)\n",
    "train_id = explode_categoricals(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transaction = pd.read_csv(\"./data/train_transaction.csv\")\n",
    "\n",
    "train_transaction[\"P_email_region\"] = train_transaction[\"P_emaildomain\"].apply(get_email_region)\n",
    "train_transaction[\"P_email_site\"] = train_transaction[\"P_emaildomain\"].apply(get_email_site)\n",
    "\n",
    "train_transaction[\"R_email_region\"] = train_transaction[\"R_emaildomain\"].apply(get_email_region)\n",
    "train_transaction[\"R_email_site\"] = train_transaction[\"R_emaildomain\"].apply(get_email_site)\n",
    "\n",
    "train_transaction = explode_categoricals(train_transaction.drop([\"P_emaildomain\", \"R_emaildomain\"], axis=1), keep_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_id.merge(right=train_transaction, on=\"TransactionID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
